{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORD-NER Token Classification\n",
    "\n",
    "The following notebook fine-tunes (<a href=\"https://huggingface.co/medicalai/ClinicalBERT\" >ClinicalBERT</a>) on the entity recognition (token classification) task using the CORD-\n",
    "NER dataset. The dataset was downloaded from Kaggle at:\n",
    "\n",
    "<a href=\"https://www.kaggle.com/datasets/sushilkumarinfo/covid-ner-data-set\">Covid NER Data Set</a>\n",
    "\n",
    "This notebooks is based on the following huggingface tutorial:\n",
    "\n",
    "<a href=\"https://huggingface.co/learn/nlp-course/en/chapter7/2?fw=pt#using-the-fine-tuned-model\">Token classification tutorial</a>\n",
    "\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\canti\\datascience\\HuggingFacePEFTProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['doc_id', 'sent_id', 'sent_tokens', 'labels'],\n",
       "        num_rows: 2568124\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['doc_id', 'sent_id', 'sent_tokens', 'labels'],\n",
       "        num_rows: 321016\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['doc_id', 'sent_id', 'sent_tokens', 'labels'],\n",
       "        num_rows: 321015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "cord_ner_dataset = load_from_disk('./data/cord-ner') \n",
    "cord_ner_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-CARDINAL',\n",
       " 'I-CARDINAL',\n",
       " 'B-ORGANISM',\n",
       " 'I-ORGANISM',\n",
       " 'B-CELL',\n",
       " 'I-CELL',\n",
       " 'B-BACTERIUM',\n",
       " 'I-BACTERIUM',\n",
       " 'B-LABORATORY_OR_TEST_RESULT',\n",
       " 'I-LABORATORY_OR_TEST_RESULT',\n",
       " 'B-CELL_COMPONENT',\n",
       " 'I-CELL_COMPONENT',\n",
       " 'B-PERSON',\n",
       " 'I-PERSON',\n",
       " 'B-MACHINE_ACTIVITY',\n",
       " 'I-MACHINE_ACTIVITY',\n",
       " 'B-SIGN_OR_SYMPTOM',\n",
       " 'I-SIGN_OR_SYMPTOM',\n",
       " 'B-BODY_SUBSTANCE',\n",
       " 'I-BODY_SUBSTANCE',\n",
       " 'B-TIME',\n",
       " 'I-TIME',\n",
       " 'B-SUBSTRATE',\n",
       " 'I-SUBSTRATE',\n",
       " 'B-CELL_FUNCTION',\n",
       " 'I-CELL_FUNCTION',\n",
       " 'B-ORDINAL',\n",
       " 'I-ORDINAL',\n",
       " 'B-HUMAN-CAUSED_PHENOMENON_OR_PROCESS',\n",
       " 'I-HUMAN-CAUSED_PHENOMENON_OR_PROCESS',\n",
       " 'B-EVOLUTION',\n",
       " 'I-EVOLUTION',\n",
       " 'B-IMMUNE_RESPONSE',\n",
       " 'I-IMMUNE_RESPONSE',\n",
       " 'B-EDUCATIONAL_ACTIVITY',\n",
       " 'I-EDUCATIONAL_ACTIVITY',\n",
       " 'B-FOOD',\n",
       " 'I-FOOD',\n",
       " 'B-LANGUAGE',\n",
       " 'I-LANGUAGE',\n",
       " 'B-GPE',\n",
       " 'I-GPE',\n",
       " 'B-BODY_PART_ORGAN_OR_ORGAN_COMPONENT',\n",
       " 'I-BODY_PART_ORGAN_OR_ORGAN_COMPONENT',\n",
       " 'B-SOCIAL_BEHAVIOR',\n",
       " 'I-SOCIAL_BEHAVIOR',\n",
       " 'B-EVENT',\n",
       " 'I-EVENT',\n",
       " 'B-TISSUE',\n",
       " 'I-TISSUE',\n",
       " 'B-FAC',\n",
       " 'I-FAC',\n",
       " 'B-MONEY',\n",
       " 'I-MONEY',\n",
       " 'B-MATERIAL',\n",
       " 'I-MATERIAL',\n",
       " 'B-DAILY_OR_RECREATIONAL_ACTIVITY',\n",
       " 'I-DAILY_OR_RECREATIONAL_ACTIVITY',\n",
       " 'B-ORGAN_OR_TISSUE_FUNCTION',\n",
       " 'I-ORGAN_OR_TISSUE_FUNCTION',\n",
       " 'B-GENE_OR_GENOME',\n",
       " 'I-GENE_OR_GENOME',\n",
       " 'B-DIAGNOSTIC_PROCEDURE',\n",
       " 'I-DIAGNOSTIC_PROCEDURE',\n",
       " 'B-THERAPEUTIC_OR_PREVENTIVE_PROCEDURE',\n",
       " 'I-THERAPEUTIC_OR_PREVENTIVE_PROCEDURE',\n",
       " 'B-VIRAL_PROTEIN',\n",
       " 'I-VIRAL_PROTEIN',\n",
       " 'B-INJURY_OR_POISONING',\n",
       " 'I-INJURY_OR_POISONING',\n",
       " 'B-GROUP',\n",
       " 'I-GROUP',\n",
       " 'B-LIVESTOCK',\n",
       " 'I-LIVESTOCK',\n",
       " 'B-DATE',\n",
       " 'I-DATE',\n",
       " 'B-ARCHAEON',\n",
       " 'I-ARCHAEON',\n",
       " 'B-RESEARCH_ACTIVITY',\n",
       " 'I-RESEARCH_ACTIVITY',\n",
       " 'B-INDIVIDUAL_BEHAVIOR',\n",
       " 'I-INDIVIDUAL_BEHAVIOR',\n",
       " 'B-PHYSICAL_SCIENCE',\n",
       " 'I-PHYSICAL_SCIENCE',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'B-GOVERNMENTAL_OR_REGULATORY_ACTIVITY',\n",
       " 'I-GOVERNMENTAL_OR_REGULATORY_ACTIVITY',\n",
       " 'B-EUKARYOTE',\n",
       " 'I-EUKARYOTE',\n",
       " 'B-CORONAVIRUS',\n",
       " 'I-CORONAVIRUS',\n",
       " 'B-WILDLIFE',\n",
       " 'I-WILDLIFE',\n",
       " 'B-EXPERIMENTAL_MODEL_OF_DISEASE',\n",
       " 'I-EXPERIMENTAL_MODEL_OF_DISEASE',\n",
       " 'B-NORP',\n",
       " 'I-NORP',\n",
       " 'B-QUANTITY',\n",
       " 'I-QUANTITY',\n",
       " 'B-LAW',\n",
       " 'I-LAW',\n",
       " 'B-CELL_OR_MOLECULAR_DYSFUNCTION',\n",
       " 'I-CELL_OR_MOLECULAR_DYSFUNCTION',\n",
       " 'B-PERCENT',\n",
       " 'I-PERCENT',\n",
       " 'B-ANATOMICAL_STRUCTURE',\n",
       " 'I-ANATOMICAL_STRUCTURE',\n",
       " 'B-VIRUS',\n",
       " 'I-VIRUS',\n",
       " 'B-WORK_OF_ART',\n",
       " 'I-WORK_OF_ART',\n",
       " 'B-LABORATORY_PROCEDURE',\n",
       " 'I-LABORATORY_PROCEDURE',\n",
       " 'B-GROUP_ATTRIBUTE',\n",
       " 'I-GROUP_ATTRIBUTE',\n",
       " 'B-DISEASE_OR_SYNDROME',\n",
       " 'I-DISEASE_OR_SYNDROME',\n",
       " 'B-MOLECULAR_FUNCTION',\n",
       " 'I-MOLECULAR_FUNCTION',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'B-PRODUCT',\n",
       " 'I-PRODUCT',\n",
       " 'B-CHEMICAL',\n",
       " 'I-CHEMICAL']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = cord_ner_dataset[\"train\"].features[\"labels\"]\n",
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "path_to_model = \"./models/ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align labels with tokens. Special tokens will get the label -100. It is a label index that will be ignored by the loss function (cross-entropy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess the whole dataset, it is necessary to tokenize all the inputs and apply align_labels_with_tokens() on all the labels. To take advantage of the speed of the fast tokenizer, it’s best to tokenize in batches.  So, we use the following function that processes a list of examples and use the Dataset.map() method with the option batched=True. The word_ids() function needs to get the index of the example we want the word IDs of when the inputs to the tokenizer are lists of texts (or in this case, list of lists of words.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sent_tokens\"], truncation=True, max_length=96, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"labels\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding is not done at this step yet. It will be done at the data collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2568124/2568124 [04:21<00:00, 9837.25 examples/s] \n",
      "Map: 100%|██████████| 321016/321016 [00:33<00:00, 9593.46 examples/s] \n",
      "Map: 100%|██████████| 321015/321015 [00:32<00:00, 9756.55 examples/s] \n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = cord_ner_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=cord_ner_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2568124\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 321016\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 321015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "To have the Trainer compute a metric every epoch, the function compute_metrics() is defined. It takes the arrays of predictions and labels, and returns a dictionary with the metric names and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric does not behave like the standard accuracy: it will actually take the lists of labels as strings, not integers, so we will need to fully decode the predictions and labels before passing them to the metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This compute_metrics() function first takes the argmax of the logits to convert them to predictions (as usual, the logits and the probabilities are in the same order, so we don’t need to apply the softmax). Then we have to convert both labels and predictions from integers to strings. We remove all the values where the label is -100, then pass the results to the metric.compute() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "\n",
    "Since we are working on a token classification problem, we will use the AutoModelForTokenClassification class. The main thing to remember when defining this model is to pass along some information on the number of labels we have. The easiest way to do this is to pass that number with the num_labels argument, but if we want a nice inference widget working like the one we saw at the beginning of this section, it’s better to set the correct label correspondences instead.\n",
    "\n",
    "They should be set by two dictionaries, id2label and label2id, which contain the mappings from ID to label and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at ./models/ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    path_to_model,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader definition\n",
    "\n",
    "The data loader will generate batch sizes of 32 examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=32,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer definition\n",
    "\n",
    "We choose an initial learning rate of 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move model, optimizer, and both dataloaders to accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler\n",
    "\n",
    "We choose to train for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "To simplify the evaluation part, we define the following postprocess() function that takes predictions and labels and converts them to lists of strings, like the metric object expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the output directory where model checkpoints will go: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./models/clinicalbert-finetuned-cord-ner\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 80254/240762 [7:08:58<15:15:03,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.8077804519750881, 'recall': 0.7637188743620039, 'f1': 0.7851319656012556, 'accuracy': 0.9134144878001901}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 160508/240762 [14:27:52<7:48:24,  2.86it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: {'precision': 0.830607309234364, 'recall': 0.7868277971285362, 'f1': 0.808125057793943, 'accuracy': 0.9239892663781595}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240762/240762 [21:50:48<00:00,  2.42it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: {'precision': 0.8375507991885777, 'recall': 0.7982051615540402, 'f1': 0.8174047804447852, 'accuracy': 0.9282542328741817}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        #repo.push_to_hub(\n",
    "        #    commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        #)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'CARDINAL',\n",
       "  'score': 0.5394215,\n",
       "  'word': 'all five',\n",
       "  'start': 0,\n",
       "  'end': 8},\n",
       " {'entity_group': 'CHEMICAL',\n",
       "  'score': 0.92919856,\n",
       "  'word': 'amino acid tryptophan',\n",
       "  'start': 41,\n",
       "  'end': 62},\n",
       " {'entity_group': 'CHEMICAL',\n",
       "  'score': 0.92330784,\n",
       "  'word': 'escherichia',\n",
       "  'start': 66,\n",
       "  'end': 77},\n",
       " {'entity_group': 'GENE_OR_GENOME',\n",
       "  'score': 0.99423695,\n",
       "  'word': 'trp',\n",
       "  'start': 121,\n",
       "  'end': 124}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"./models/clinicalbert-finetuned-cord-ner\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "token_classifier(\"All five of the genes needed to make the amino acid tryptophan in Escherichia coli are located next to each other in the trp operon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "path_to_model = \"./models/clinicalbert-finetuned-cord-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 321016/321016 [01:14<00:00, 4281.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_dataset = cord_ner_dataset[\"test\"].map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=cord_ner_dataset[\"test\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    path_to_model,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_test_dataset, collate_fn=data_collator, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8374526946399435, 'recall': 0.79827810498694, 'f1': 0.8173962980288354, 'accuracy': 0.9281765313397233}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    labels = batch[\"labels\"]\n",
    "\n",
    "    # Necessary to pad predictions and labels for being gathered\n",
    "    # predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "    # labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "    # predictions_gathered = accelerator.gather(predictions)\n",
    "    # labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "    true_predictions, true_labels = postprocess(predictions, labels)\n",
    "    metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "results = metric.compute()\n",
    "print(\n",
    "    {\n",
    "        key: results[f\"overall_{key}\"]\n",
    "        for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for individual classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANATOMICAL_STRUCTURE': {'precision': 0.7191666666666666,\n",
       "  'recall': 0.7570175438596491,\n",
       "  'f1': 0.7376068376068375,\n",
       "  'number': 1140},\n",
       " 'ARCHAEON': {'precision': 1.0,\n",
       "  'recall': 0.9782608695652174,\n",
       "  'f1': 0.989010989010989,\n",
       "  'number': 46},\n",
       " 'BACTERIUM': {'precision': 0.8599182004089979,\n",
       "  'recall': 0.788191190253046,\n",
       "  'f1': 0.8224938875305624,\n",
       "  'number': 1067},\n",
       " 'BODY_PART_ORGAN_OR_ORGAN_COMPONENT': {'precision': 0.8726891557080236,\n",
       "  'recall': 0.8365762309308487,\n",
       "  'f1': 0.854251200970104,\n",
       "  'number': 10947},\n",
       " 'BODY_SUBSTANCE': {'precision': 0.9775072770574226,\n",
       "  'recall': 0.9639874739039666,\n",
       "  'f1': 0.9707003021941926,\n",
       "  'number': 3832},\n",
       " 'CARDINAL': {'precision': 0.8973055078589354,\n",
       "  'recall': 0.844080811092888,\n",
       "  'f1': 0.8698797649077429,\n",
       "  'number': 80484},\n",
       " 'CELL': {'precision': 0.854814158802203,\n",
       "  'recall': 0.8192186298172559,\n",
       "  'f1': 0.8366379543853947,\n",
       "  'number': 37703},\n",
       " 'CELL_COMPONENT': {'precision': 0.8203454894433782,\n",
       "  'recall': 0.8019764823617713,\n",
       "  'f1': 0.8110569928521728,\n",
       "  'number': 23982},\n",
       " 'CELL_FUNCTION': {'precision': 0.9825834542815675,\n",
       "  'recall': 0.9753035604033752,\n",
       "  'f1': 0.9789299731460442,\n",
       "  'number': 4859},\n",
       " 'CELL_OR_MOLECULAR_DYSFUNCTION': {'precision': 0.9919328815747015,\n",
       "  'recall': 0.9900161030595813,\n",
       "  'f1': 0.9909735654416505,\n",
       "  'number': 3105},\n",
       " 'CHEMICAL': {'precision': 0.8421292472444533,\n",
       "  'recall': 0.7856516540454365,\n",
       "  'f1': 0.8129106755010583,\n",
       "  'number': 225810},\n",
       " 'CORONAVIRUS': {'precision': 0.9981246218995765,\n",
       "  'recall': 0.9934368978805395,\n",
       "  'f1': 0.9957752429235319,\n",
       "  'number': 16608},\n",
       " 'DAILY_OR_RECREATIONAL_ACTIVITY': {'precision': 0.9911111111111112,\n",
       "  'recall': 0.9886699507389163,\n",
       "  'f1': 0.9898890258939581,\n",
       "  'number': 2030},\n",
       " 'DATE': {'precision': 0.8221073617366905,\n",
       "  'recall': 0.793740643045555,\n",
       "  'f1': 0.8076750090678274,\n",
       "  'number': 70135},\n",
       " 'DIAGNOSTIC_PROCEDURE': {'precision': 0.9549104385423101,\n",
       "  'recall': 0.9142519219396806,\n",
       "  'f1': 0.9341389728096676,\n",
       "  'number': 1691},\n",
       " 'DISEASE_OR_SYNDROME': {'precision': 0.8458849991348982,\n",
       "  'recall': 0.8056202487146812,\n",
       "  'f1': 0.8252617837871294,\n",
       "  'number': 91028},\n",
       " 'EDUCATIONAL_ACTIVITY': {'precision': 0.9536082474226805,\n",
       "  'recall': 0.9635416666666666,\n",
       "  'f1': 0.9585492227979275,\n",
       "  'number': 192},\n",
       " 'EUKARYOTE': {'precision': 0.9521703068841582,\n",
       "  'recall': 0.9232006433453961,\n",
       "  'f1': 0.9374617216740387,\n",
       "  'number': 14922},\n",
       " 'EVENT': {'precision': 0.07395498392282958,\n",
       "  'recall': 0.22330097087378642,\n",
       "  'f1': 0.11111111111111112,\n",
       "  'number': 103},\n",
       " 'EVOLUTION': {'precision': 0.9947657347121154,\n",
       "  'recall': 0.98933468765871,\n",
       "  'f1': 0.9920427780253358,\n",
       "  'number': 7876},\n",
       " 'EXPERIMENTAL_MODEL_OF_DISEASE': {'precision': 0.9668508287292817,\n",
       "  'recall': 0.9562841530054644,\n",
       "  'f1': 0.9615384615384616,\n",
       "  'number': 366},\n",
       " 'FAC': {'precision': 0.1016949152542373,\n",
       "  'recall': 0.24519230769230768,\n",
       "  'f1': 0.1437632135306554,\n",
       "  'number': 416},\n",
       " 'FOOD': {'precision': 0.9233971690258118,\n",
       "  'recall': 0.913509060955519,\n",
       "  'f1': 0.9184265010351967,\n",
       "  'number': 1214},\n",
       " 'GENE_OR_GENOME': {'precision': 0.8162319202124618,\n",
       "  'recall': 0.7446257716415221,\n",
       "  'f1': 0.778786338560714,\n",
       "  'number': 210914},\n",
       " 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY': {'precision': 0.9656419529837251,\n",
       "  'recall': 0.9638989169675091,\n",
       "  'f1': 0.964769647696477,\n",
       "  'number': 554},\n",
       " 'GPE': {'precision': 0.714789659348181,\n",
       "  'recall': 0.7249038872276805,\n",
       "  'f1': 0.7198112457251928,\n",
       "  'number': 18728},\n",
       " 'GROUP': {'precision': 0.9928015705664218,\n",
       "  'recall': 0.9862044059227157,\n",
       "  'f1': 0.9894919921733459,\n",
       "  'number': 27690},\n",
       " 'GROUP_ATTRIBUTE': {'precision': 0.9493670886075949,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.974025974025974,\n",
       "  'number': 75},\n",
       " 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS': {'precision': 0.9684813753581661,\n",
       "  'recall': 0.9684813753581661,\n",
       "  'f1': 0.9684813753581661,\n",
       "  'number': 349},\n",
       " 'IMMUNE_RESPONSE': {'precision': 0.9951219512195122,\n",
       "  'recall': 0.9894018322256153,\n",
       "  'f1': 0.992253647991353,\n",
       "  'number': 5567},\n",
       " 'INDIVIDUAL_BEHAVIOR': {'precision': 0.9458896982310093,\n",
       "  'recall': 0.9568421052631579,\n",
       "  'f1': 0.9513343799058084,\n",
       "  'number': 950},\n",
       " 'INJURY_OR_POISONING': {'precision': 0.889168765743073,\n",
       "  'recall': 0.8424821002386634,\n",
       "  'f1': 0.8651960784313725,\n",
       "  'number': 419},\n",
       " 'LABORATORY_OR_TEST_RESULT': {'precision': 0.9719512195121951,\n",
       "  'recall': 0.9381989405532666,\n",
       "  'f1': 0.9547768793051812,\n",
       "  'number': 1699},\n",
       " 'LABORATORY_PROCEDURE': {'precision': 0.9648622981956315,\n",
       "  'recall': 0.9474665837737022,\n",
       "  'f1': 0.9560853199498118,\n",
       "  'number': 9651},\n",
       " 'LANGUAGE': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.8421052631578947,\n",
       "  'f1': 0.744186046511628,\n",
       "  'number': 114},\n",
       " 'LAW': {'precision': 0.26413255360623783,\n",
       "  'recall': 0.3370646766169154,\n",
       "  'f1': 0.29617486338797816,\n",
       "  'number': 804},\n",
       " 'LIVESTOCK': {'precision': 0.9953133369041243,\n",
       "  'recall': 0.9802189107213504,\n",
       "  'f1': 0.9877084579097734,\n",
       "  'number': 7583},\n",
       " 'LOC': {'precision': 0.6177437020810514,\n",
       "  'recall': 0.6619718309859155,\n",
       "  'f1': 0.6390934844192635,\n",
       "  'number': 1704},\n",
       " 'MACHINE_ACTIVITY': {'precision': 0.993103448275862,\n",
       "  'recall': 0.9795918367346939,\n",
       "  'f1': 0.9863013698630136,\n",
       "  'number': 294},\n",
       " 'MATERIAL': {'precision': 0.9434968017057569,\n",
       "  'recall': 0.9414893617021277,\n",
       "  'f1': 0.9424920127795527,\n",
       "  'number': 940},\n",
       " 'MOLECULAR_FUNCTION': {'precision': 0.9810563162771543,\n",
       "  'recall': 0.9588448379955725,\n",
       "  'f1': 0.969823418655539,\n",
       "  'number': 9938},\n",
       " 'MONEY': {'precision': 0.39699381078691426,\n",
       "  'recall': 0.43762183235867447,\n",
       "  'f1': 0.4163189615206306,\n",
       "  'number': 1026},\n",
       " 'NORP': {'precision': 0.6829212454212454,\n",
       "  'recall': 0.6971254966113578,\n",
       "  'f1': 0.6899502717705563,\n",
       "  'number': 4279},\n",
       " 'ORDINAL': {'precision': 0.9377515427958143,\n",
       "  'recall': 0.8717884759291594,\n",
       "  'f1': 0.9035677352637022,\n",
       "  'number': 8018},\n",
       " 'ORG': {'precision': 0.5831421262230662,\n",
       "  'recall': 0.5909977815197925,\n",
       "  'f1': 0.5870436744988716,\n",
       "  'number': 37413},\n",
       " 'ORGANISM': {'precision': 0.8390232700551132,\n",
       "  'recall': 0.8165226460071514,\n",
       "  'f1': 0.8276200543642404,\n",
       "  'number': 26848},\n",
       " 'ORGAN_OR_TISSUE_FUNCTION': {'precision': 0.959332638164755,\n",
       "  'recall': 0.9523809523809523,\n",
       "  'f1': 0.9558441558441559,\n",
       "  'number': 966},\n",
       " 'PERCENT': {'precision': 0.47770700636942676,\n",
       "  'recall': 0.44466403162055335,\n",
       "  'f1': 0.46059365404298874,\n",
       "  'number': 506},\n",
       " 'PERSON': {'precision': 0.44954449894884374,\n",
       "  'recall': 0.4703653916656483,\n",
       "  'f1': 0.45971931919976117,\n",
       "  'number': 16366},\n",
       " 'PHYSICAL_SCIENCE': {'precision': 0.9802631578947368,\n",
       "  'recall': 0.9738562091503268,\n",
       "  'f1': 0.9770491803278688,\n",
       "  'number': 153},\n",
       " 'PRODUCT': {'precision': 0.31305361305361307,\n",
       "  'recall': 0.3654421768707483,\n",
       "  'f1': 0.33722536095417455,\n",
       "  'number': 3675},\n",
       " 'QUANTITY': {'precision': 0.760185020458993,\n",
       "  'recall': 0.6810104390788111,\n",
       "  'f1': 0.7184229330419066,\n",
       "  'number': 12549},\n",
       " 'RESEARCH_ACTIVITY': {'precision': 0.9910565723793677,\n",
       "  'recall': 0.9877694859038143,\n",
       "  'f1': 0.9894102990033222,\n",
       "  'number': 4824},\n",
       " 'SIGN_OR_SYMPTOM': {'precision': 0.952887537993921,\n",
       "  'recall': 0.9432117337344866,\n",
       "  'f1': 0.948024948024948,\n",
       "  'number': 2659},\n",
       " 'SOCIAL_BEHAVIOR': {'precision': 0.9837239583333334,\n",
       "  'recall': 0.9754680438992899,\n",
       "  'f1': 0.9795786061588331,\n",
       "  'number': 1549},\n",
       " 'SUBSTRATE': {'precision': 0.9901873327386262,\n",
       "  'recall': 0.9794837855724685,\n",
       "  'f1': 0.9848064766552068,\n",
       "  'number': 4533},\n",
       " 'THERAPEUTIC_OR_PREVENTIVE_PROCEDURE': {'precision': 0.9867844055986064,\n",
       "  'recall': 0.9786131299892767,\n",
       "  'f1': 0.9826817814733945,\n",
       "  'number': 16786},\n",
       " 'TIME': {'precision': 0.7670373538637012,\n",
       "  'recall': 0.7430939226519337,\n",
       "  'f1': 0.7548758243300127,\n",
       "  'number': 3620},\n",
       " 'TISSUE': {'precision': 0.7704535181557933,\n",
       "  'recall': 0.7150748147112292,\n",
       "  'f1': 0.7417319408181028,\n",
       "  'number': 14302},\n",
       " 'VIRAL_PROTEIN': {'precision': 0.9513395297977036,\n",
       "  'recall': 0.8734939759036144,\n",
       "  'f1': 0.9107563465061502,\n",
       "  'number': 1992},\n",
       " 'VIRUS': {'precision': 0.942974527526705,\n",
       "  'recall': 0.8909937888198758,\n",
       "  'f1': 0.91624750499002,\n",
       "  'number': 12880},\n",
       " 'WILDLIFE': {'precision': 0.9895373169030458,\n",
       "  'recall': 0.9840462427745664,\n",
       "  'f1': 0.9867841409691629,\n",
       "  'number': 4325},\n",
       " 'WORK_OF_ART': {'precision': 0.08123791102514506,\n",
       "  'recall': 0.2709677419354839,\n",
       "  'f1': 0.125,\n",
       "  'number': 155},\n",
       " 'overall_precision': 0.8374526946399435,\n",
       " 'overall_recall': 0.79827810498694,\n",
       " 'overall_f1': 0.8173962980288354,\n",
       " 'overall_accuracy': 0.9281765313397233}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
